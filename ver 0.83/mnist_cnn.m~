%Convolutional neural network for handwriten digits recognition: training
%and simulation.
%(c)Mikhail Sirotenko, 2009.
%This program implements the convolutional neural network for MNIST handwriten 
%digits recognition, created by Yann LeCun. CNN class allows to make your
%own convolutional neural net, defining arbitrary structure and parameters.
%It is assumed that MNIST database is located in './MNIST' directory.
%References:
%1. Y. LeCun, L. Bottou, G. Orr and K. Muller: Efficient BackProp, in Orr, G.
%and Muller K. (Eds), Neural Networks: Tricks of the trade, Springer, 1998
%URL:http://yann.lecun.com/exdb/publis/index.html
%2. Y. LeCun, L. Bottou, Y. Bengio and P. Haffner: Gradient-Based Learning
%Applied to Document Recognition, Proceedings of the IEEE, 86(11):2278-2324, November 1998
%URL:http://yann.lecun.com/exdb/publis/index.html
%3. Patrice Y. Simard, Dave Steinkraus, John C. Platt: Best Practices for
%Convolutional Neural Networks Applied to Visual Document Analysis
%URL:http://research.microsoft.com/apps/pubs/?id=68920
%4. Thanks to Mike O'Neill for his great article, wich is summarize and
%generalize all the information in 1-3 for better understandig for
%programming:
%URL: http://www.codeproject.com/KB/library/NeuralNetRecognition.aspx
%5. Also thanks to Jake Bouvrie for his "Notes on Convolutional Neural
%Networks", particulary for the idea to debug the neural network using
%finite differences
%URL: http://web.mit.edu/jvb/www/cv.html

clear;
clc;

% the number of images to use for training and testing. Due to later implementation
% details, trainNum should never be less than testNum (they can be the same). 
% The maximum trainNum is 60,000 and the maximum testNum is 10000 (because that
% is all of the images provided in the MNIST dataset. 
% If you change these numbers to their respective maximums, be prepared to wait
% for quite a long time. As submitted, they are set to considerably lower values
% to encourage a runtime measured in minutes, not hours. However, this code does
% function correctly on the maximum dataset if you are willing to wait.
trainNum = 10000
testNum = 1000

% First, need to read in the dataset. Using readMNIST.m (provided) to obtain
% the training images, training labels, testing images, and testing labels. 
[I_train,labels_train,I_test,labels_test] = readMNIST(trainNum); 

% Defining CNN with structure described in LeCun et al
% Total number of layers
numLayers = 8; 
% Number of subsampling layers
numSLayers = 3; 
% Number of convolutional layers
numCLayers = 3; 
% Number of fully-connected layers
numFLayers = 2;
% Number of input images (to be processed simultaneously)
% I do not believe this CNN implementation is capable of 
% doing more than 1
numInputs = 1; 
% Image width
InputWidth = 32; 
% Image height
InputHeight = 32;
% Number of outputs
numOutputs = 10; 
% Create an empty convolutional neural network with the specified structure
% Using cnn.m and associated methods (provided) to manage the implementation details
dignet = cnn(numLayers,numFLayers,numInputs,InputWidth,InputHeight,numOutputs);

% With the skeleton in place, we now have to define each layer

% Documentation of this CNN specifies that layers are in pairs (first
% subsampling then convolutional). So, we have to make a dummy first layer
% that is of the subsampling type, but doesn't actually change anything.
dignet.SLayer{1}.SRate = 1;
dignet.SLayer{1}.WS{1} = ones(size(dignet.SLayer{1}.WS{1}));
dignet.SLayer{1}.BS{1} = zeros(size(dignet.SLayer{1}.BS{1}));
dignet.SLayer{1}.TransfFunc = 'purelin';

% Second layer - Convolution layer
% 6 different kernels with 5x5 size 
% input single image of size 32x32
% output 6 images of size 28x28
dignet.CLayer{2}.numKernels = 6;
dignet.CLayer{2}.KernWidth = 5;
dignet.CLayer{2}.KernHeight = 5;

% Third layer - Subsampling layer
% subsamples by half
% input 6 images of size 28x28
% output 6 images of size 14x14
dignet.SLayer{3}.SRate = 2;

% Forth layer - Convolution layer
% 16 kernels with 5x5 size 
% input 6 images of size 14x14
% output 16 images of size 10x10
dignet.CLayer{4}.numKernels = 16;
dignet.CLayer{4}.KernWidth = 5;
dignet.CLayer{4}.KernHeight = 5;

% Fifth layer - Subsampling layer
% subsamples by half
% input 16 images of size 10x10
% output 16 images of size 5x5
dignet.SLayer{5}.SRate = 2;

% Sixth layer - Convolutional layer
% convolving with 120 different 5x5 kernels
% outputs 120 feature mapsof size 1x1
dignet.CLayer{6}.numKernels = 120;
dignet.CLayer{6}.KernWidth = 5;
dignet.CLayer{6}.KernHeight = 5;

% Seventh layer - fully connected, 84 neurons
dignet.FLayer{7}.numNeurons = 84;

% Eighth layer - fully connected, 10 output neurons
% The resulting 10 outputs correspond to the 10 classification possibilities!
dignet.FLayer{8}.numNeurons = 10;

% The network needs to be initialized
dignet = init(dignet);

% The following several updates are parameters extracted directly from 
% either the LeCun paper on the CNN documentation. For the following 9 
% assignments, I took the recommendations at face value and did not 
% attempt to alter them.

% apparently the generalisation is better if there's unsimmetry in
% layers connections. This kind of connection map is suggested:
dignet.CLayer{4}.ConMap = ...
[1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1;
 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1;
 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1;
 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1;
 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1; 
 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1; 
]';
% pertaining to the dummy first layer
dignet.SLayer{1}.WS{1} = ones(size(dignet.SLayer{1}.WS{1}));
dignet.SLayer{1}.BS{1} = zeros(size(dignet.SLayer{1}.BS{1}));
% relating to learning parameters
dignet.epochs = 3;
dignet.mu = 0.001;
dignet.teta =  0.0005;
% relating to the final layers of the network
dignet.HcalcMode = 0;
dignet.Hrecalc = 300;
dignet.HrecalcSamplesNum = 50;
dignet.teta_dec = 0.4;

%Images preprocessing. Resulting images have 0 mean and 1 standard
%deviation. Go inside the preproc_data for details
% Using preproc_data.m (provided), which takes the Images and Labels and
% processes them so the images have 0 mean and 1 standard deviations.
% Resulting images are 32x32, which is slightly larger than the input 28x28.
[I_train_p, labels_train_p] = preproc_data(I_train,trainNum,labels_train,0);
[I_test_p, labels_test_p] = preproc_data(I_test,testNum,labels_test,0);
% finally, actually perform the training
dignet = train(dignet,I_p,labels_train_p,I_test_p,labels_test_p);
