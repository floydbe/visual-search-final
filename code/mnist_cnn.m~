% An implementation of Convolutional Neural Network training and testing 
% based on the MNIST handwritten digit dataset. 

% This implementation is based on the Convlutional Neural Network (CNN)
% Class provided by Mihail Sirotenko. It is available at:
% http://www.mathworks.com/matlabcentral/fileexchange/24291-cnn-convolutional-neural-network-class.
% The implementation details of CNN as well as the definitions of several 
% associated methods come from here. Any attributes of the dignet object 
% defined below belong to Sirtenko's implementation. Any other instances in
% which this program dishes out to a provided function are marked clearly
% in their documentation. The entire class is included in the zipfile
% submission (including many parts that are not actually used), so there is
% no need to download anything. 

% A notable feature of this class's training implementation is a GUI
% displaying, among other things, the percentage completion of the training
% process. Note that this GUI is not my implementation, but it is very
% useful in predicting the timing of the training process. However, aspects
% the GUI can cause warnings. Be sure to close the GUI before attemping 
% subsequent runs. There is no GUI for the testing process (which begins as
% soon as the training is complete).

% The other primary source for this implementation is the CNN structure defined in:
%	Y. LeCun, L. Bottou, Y. Bengio and P. Haffner: Gradient-Based Learning
%	Applied to Document Recognition, Proceedings of the IEEE, 86(11):2278-2324, November 1998
% available at http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf

clear;
clc;

% the number of images to use for training and testing. Due to later implementation
% details, trainNum should never be less than testNum (they can be the same). 
% The maximum trainNum is 60,000 and the maximum testNum is 10000 (because that
% is all of the images provided in the MNIST dataset. 
% If you change these numbers to their respective maximums, be prepared to wait
% for quite a long time. As submitted, they are set to considerably lower values
% to encourage a runtime measured in minutes, not hours. However, this code does
% function correctly on the maximum dataset if you are willing to wait.
trainNum = 1500;
testNum = 1500;

% First, need to read in the dataset. Using readMNIST.m (provided) to obtain
% the training images, training labels, testing images, and testing labels. 
[I_train,labels_train,I_test,labels_test] = readMNIST(trainNum); 

% Defining CNN with structure described in LeCun et al
% Total number of layers
numLayers = 8; 
% Number of subsampling layers
numSLayers = 3; 
% Number of convolutional layers
numCLayers = 3; 
% Number of fully-connected layers
numFLayers = 2;
% Number of input images (to be processed simultaneously)
% I do not believe this CNN implementation is capable of 
% doing more than 1
numInputs = 1; 
% Image width
InputWidth = 32; 
% Image height
InputHeight = 32;
% Number of outputs
numOutputs = 10; 
% Create an empty convolutional neural network with the specified structure
% Using cnn.m and associated methods (provided) to manage the implementation details
dignet = cnn(numLayers,numFLayers,numInputs,InputWidth,InputHeight,numOutputs);

% With the skeleton in place, we now have to define each layer

% Documentation of this CNN specifies that layers are in pairs (first
% subsampling then convolutional). So, we have to make a dummy first layer
% that is of the subsampling type, but doesn't actually change anything.
dignet.SLayer{1}.SRate = 1;
dignet.SLayer{1}.WS{1} = ones(size(dignet.SLayer{1}.WS{1}));
dignet.SLayer{1}.BS{1} = zeros(size(dignet.SLayer{1}.BS{1}));
dignet.SLayer{1}.TransfFunc = 'purelin';

% Second layer - Convolution layer
% 6 different kernels with 5x5 size 
% input single image of size 32x32
% output 6 images of size 28x28
dignet.CLayer{2}.numKernels = 6;
dignet.CLayer{2}.KernWidth = 5;
dignet.CLayer{2}.KernHeight = 5;

% Third layer - Subsampling layer
% subsamples by half
% input 6 images of size 28x28
% output 6 images of size 14x14
dignet.SLayer{3}.SRate = 2;

% Forth layer - Convolution layer
% 16 kernels with 5x5 size 
% input 6 images of size 14x14
% output 16 images of size 10x10
dignet.CLayer{4}.numKernels = 16;
dignet.CLayer{4}.KernWidth = 5;
dignet.CLayer{4}.KernHeight = 5;

% Fifth layer - Subsampling layer
% subsamples by half
% input 16 images of size 10x10
% output 16 images of size 5x5
dignet.SLayer{5}.SRate = 2;

% Sixth layer - Convolutional layer
% convolving with 120 different 5x5 kernels
% outputs 120 feature mapsof size 1x1
dignet.CLayer{6}.numKernels = 120;
dignet.CLayer{6}.KernWidth = 5;
dignet.CLayer{6}.KernHeight = 5;

% Seventh layer - fully connected, 84 neurons
dignet.FLayer{7}.numNeurons = 84;

% Eighth layer - fully connected, 10 output neurons
% The resulting 10 outputs correspond to the 10 classification possibilities!
dignet.FLayer{8}.numNeurons = 10;

% The network needs to be initialized
dignet = init(dignet);

% The following several updates are parameters extracted directly from 
% either the LeCun paper on the CNN documentation. For the following 9 
% assignments, I took the recommendations at face value and did not 
% attempt to alter them.

% apparently the generalisation is better if there's unsimmetry in
% layers connections. This kind of connection map is suggested:
dignet.CLayer{4}.ConMap = ...
[1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1;
 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1;
 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1;
 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1;
 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1; 
 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1; 
]';
% pertaining to the dummy first layer
dignet.SLayer{1}.WS{1} = ones(size(dignet.SLayer{1}.WS{1}));
dignet.SLayer{1}.BS{1} = zeros(size(dignet.SLayer{1}.BS{1}));
% relating to learning parameters
dignet.epochs = 3;
dignet.mu = 0.001;
dignet.teta =  0.0005;
% relating to the final layers of the network
dignet.HcalcMode = 0;
dignet.Hrecalc = 300;
dignet.HrecalcSamplesNum = 50;
dignet.teta_dec = 0.4;

%Images preprocessing. Resulting images have 0 mean and 1 standard
%deviation. Go inside the preproc_data for details
% Using preproc_data.m (provided), which takes the Images and Labels and
% processes them so the images have 0 mean and 1 standard deviations.
% Resulting images are 32x32, which is slightly larger than the input 28x28.
[I_train_p, labels_train_p] = preproc_data(I_train,trainNum,labels_train,0);
[I_test_p, labels_test_p] = preproc_data(I_test,testNum,labels_test,0);
% finally, actually perform the training
dignet = train(dignet,I_train_p,labels_train_p,I_test_p,labels_test_p);

% Now, with dignet trained, we just need to evaluate its performance.
% The idea is simple: just loop through the test set, have dignet predict
% the proper label, then check if that matches the test label for that
% image. The number of correct classifications over the number of test inp
correct=0;
[I_testp,labnew] = preproc_data(I_test,testNum,labels_test,0);
for t=1:testNum
    [out(t,:), dignet] = sim(dignet,I_testp{t});    
    if(find(out(t,:)==max(out(t,:)))==(labnew(t)+1))
        correct=correct+1;
    end
end
acc = correct/testNum